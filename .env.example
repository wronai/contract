# ============================================================================
# Reclapp 2.1.0 - Environment Configuration
# ============================================================================
# Copy this file to .env and customize values as needed.
# Variables marked [REQUIRED] must be set in production.
# Variables marked [SECRET] should never be committed to version control.

# ============================================================================
# GENERAL
# ============================================================================
NODE_ENV=development
TZ=UTC

# ============================================================================
# API SERVER
# ============================================================================
PORT=8080
HOST=0.0.0.0
API_PREFIX=/api/v1
CORS_ORIGIN=http://localhost:3000

# ============================================================================
# FRONTEND
# ============================================================================
FRONTEND_PORT=3000
VITE_API_URL=http://localhost:8080

# ============================================================================
# EVENT STORE
# ============================================================================
EVENTSTORE_URL=esdb://localhost:2113?tls=false
EVENTSTORE_HTTP_PORT=2113
EVENTSTORE_TCP_PORT=1113
EVENTSTORE_INSECURE=true

# ============================================================================
# DATABASE (PostgreSQL)
# ============================================================================
DATABASE_URL=postgresql://reclapp:reclapp@localhost:5432/reclapp
POSTGRES_USER=reclapp
POSTGRES_PASSWORD=reclapp
POSTGRES_DB=reclapp
POSTGRES_PORT=5432

# ============================================================================
# REDIS
# ============================================================================
REDIS_URL=redis://localhost:6379
REDIS_PORT=6379

# ============================================================================
# RABBITMQ (Multi-Agent)
# ============================================================================
RABBITMQ_URL=amqp://reclapp:reclapp@localhost:5672
RABBITMQ_USER=reclapp
RABBITMQ_PASSWORD=reclapp
RABBITMQ_PORT=5672
RABBITMQ_MANAGEMENT_PORT=15672

# ============================================================================
# MQTT (IoT/Hardware)
# ============================================================================
MQTT_BROKER=mqtt://localhost:1883
MQTT_PORT=1883
MQTT_WS_PORT=9001
MQTT_USERNAME=
MQTT_PASSWORD=

# ============================================================================
# INFLUXDB (Time Series - IoT)
# ============================================================================
INFLUXDB_URL=http://localhost:8086
INFLUXDB_PORT=8086
INFLUXDB_ORG=reclapp
INFLUXDB_BUCKET=iot_metrics
INFLUXDB_TOKEN=reclapp-token
INFLUXDB_ADMIN_USER=admin
INFLUXDB_ADMIN_PASSWORD=adminpassword

# ============================================================================
# LOGGING
# ============================================================================
LOG_LEVEL=debug
LOG_FORMAT=pretty

# ============================================================================
# SECURITY [SECRET]
# ============================================================================
JWT_SECRET=change-this-in-production-use-strong-random-string
JWT_EXPIRES_IN=7d
API_KEY=

# ============================================================================
# RATE LIMITING
# ============================================================================
RATE_LIMIT_WINDOW_MS=60000
RATE_LIMIT_MAX_REQUESTS=100

# ============================================================================
# AI CONTRACT SETTINGS
# ============================================================================
AI_CONFIDENCE_THRESHOLD=0.7
AI_MAX_ACTIONS_PER_MINUTE=60
AI_SANDBOX_MODE=true
ANOMALY_DETECTION_ENABLED=true

# ============================================================================
# CAUSAL REASONING
# ============================================================================
CAUSAL_DECAY_RATE=0.01
CAUSAL_MIN_CONFIDENCE=0.3
CAUSAL_MAX_ADJUSTMENT=0.1

# ============================================================================
# EXTERNAL APIS
# ============================================================================
KRS_API_URL=https://api-krs.ms.gov.pl
CEIDG_API_URL=https://dane.biznes.gov.pl/api/ceidg

# ============================================================================
# MONITORING & OBSERVABILITY
# ============================================================================
PROMETHEUS_ENABLED=false
PROMETHEUS_PORT=9090
GRAFANA_PORT=3001
GRAFANA_ADMIN_USER=admin
GRAFANA_ADMIN_PASSWORD=admin

# ============================================================================
# STUDIO (Gradio UI)
# ============================================================================
STUDIO_HOST=0.0.0.0
STUDIO_PORT=7860

# ============================================================================
# LLM PROVIDERS - Multi-Provider Architecture
# ============================================================================
# Supports multiple providers with priority-based fallback and rate limiting.
# Configure litellm_config.yaml for advanced routing and priorities.
#
# Default provider: ollama, openrouter, openai, anthropic, groq, together, litellm
LLM_PROVIDER=ollama

# Generation settings
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=4096
LLM_TIMEOUT_MS=60000
LLM_VERBOSE=false

# ============================================================================
# OLLAMA (Local) - Priority 10 (highest)
# ============================================================================
# Local inference, no API key needed. Best for privacy and cost.
# Install: https://ollama.ai
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=qwen2.5-coder:14b
# Recommended models: qwen2.5-coder:14b, qwen2.5-coder:7b, deepseek-coder:6.7b

# ============================================================================
# OPENROUTER (Multi-model API) - Priority 40
# Free tier available: https://openrouter.ai
# ============================================================================
OPENROUTER_API_KEY=sk-or-v1-your-key-here
OPENROUTER_MODEL=qwen/qwen-2.5-coder-32b-instruct
# Free models:
#OPENROUTER_MODEL=nvidia/nemotron-3-nano-30b-a3b:free
#OPENROUTER_MODEL=meta-llama/llama-3.3-70b-instruct:free
#OPENROUTER_MODEL=nvidia/nemotron-nano-9b-v2:free

# ============================================================================
# OPENAI - Priority 50
# https://platform.openai.com
# ============================================================================
# OPENAI_API_KEY=sk-your-key-here
# OPENAI_MODEL=gpt-4-turbo
# Alternative: gpt-4o, gpt-3.5-turbo

# ============================================================================
# ANTHROPIC - Priority 60
# https://console.anthropic.com
# ============================================================================
# ANTHROPIC_API_KEY=sk-ant-your-key-here
# ANTHROPIC_MODEL=claude-3-sonnet-20240229
# Alternative: claude-3-opus-20240229, claude-3-haiku-20240307

# ============================================================================
# GROQ (Fast Inference) - Priority 20
# https://console.groq.com - Very fast, good free tier
# ============================================================================
# GROQ_API_KEY=gsk_your-key-here
# GROQ_MODEL=llama-3.1-70b-versatile
# Alternative: llama-3.1-8b-instant, mixtral-8x7b-32768

# ============================================================================
# TOGETHER AI - Priority 30
# https://together.ai - Good for open models
# ============================================================================
# TOGETHER_API_KEY=your-key-here
# TOGETHER_MODEL=Qwen/Qwen2.5-Coder-32B-Instruct
# Alternative: meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo

# ============================================================================
# LITELLM (Universal Proxy) - Priority 70
# OpenAI-compatible proxy for any model
# ============================================================================
# LITELLM_URL=http://localhost:4000
# LITELLM_MODEL=gpt-4
# LITELLM_API_KEY=

# ============================================================================
# RATE LIMITING & PARALLEL EXECUTION
# ============================================================================
PARALLEL_MAX_CONCURRENCY=5
PARALLEL_RATE_LIMIT_PER_PROVIDER=60
PARALLEL_RATE_LIMIT_WINDOW_MS=60000
PARALLEL_LOAD_BALANCE_STRATEGY=least-loaded
# Strategies: priority, round-robin, least-loaded, random

# ============================================================================
# SENTRY (Error Tracking)
# ============================================================================
SENTRY_DSN=
SENTRY_ENVIRONMENT=development

# ============================================================================
# DOCKER COMPOSE PORT MAPPINGS
# ============================================================================
# These allow overriding host ports to avoid conflicts

# Main stack
DOCKER_API_PORT=8080
DOCKER_FRONTEND_PORT=3000
DOCKER_EVENTSTORE_HTTP_PORT=2113
DOCKER_EVENTSTORE_TCP_PORT=1113
DOCKER_REDIS_PORT=6379
DOCKER_GRAFANA_PORT=3001
DOCKER_PROMETHEUS_PORT=9090
DOCKER_MQTT_PORT=1883
DOCKER_MQTT_WS_PORT=9001

# B2B Risk Monitoring example
B2B_API_PORT=8081
B2B_DASHBOARD_PORT=3001
B2B_EVENTSTORE_HTTP_PORT=2114
B2B_EVENTSTORE_TCP_PORT=1114
B2B_POSTGRES_PORT=5433
B2B_REDIS_PORT=6380

# IoT Monitoring example
IOT_API_PORT=8082
IOT_MQTT_PORT=1884
IOT_MQTT_WS_PORT=9002
IOT_INFLUXDB_PORT=8087
IOT_EVENTSTORE_HTTP_PORT=2116
IOT_GRAFANA_PORT=3004

# Multi-Agent example
AGENT_ORCHESTRATOR_PORT=8090
AGENT_RISK_PORT=8091
AGENT_COMPLIANCE_PORT=8092
AGENT_CUSTOMER_PORT=8093
AGENT_EVENTSTORE_HTTP_PORT=2115
AGENT_REDIS_PORT=6381
AGENT_RABBITMQ_PORT=5673
AGENT_RABBITMQ_MGMT_PORT=15673
AGENT_POSTGRES_PORT=5434
AGENT_GRAFANA_PORT=3003
AGENT_PROMETHEUS_PORT=9091
