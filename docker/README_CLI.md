# Reclapp CLI Docker Container

Kontener Docker z prekonfigurowanym LiteLLM providerem do u偶ycia z LM Studio.

##  Szybki Start

### 1. Uruchom LM Studio na hocie (port 8123)

Upewnij si, 偶e LM Studio dziaa i wystawia API na `http://localhost:8123`.

### 2. Uruchom Reclapp CLI w kontenerze

```bash
# Podstawowe u偶ycie
docker compose run --rm reclapp-cli evolve --prompt "Create a todo app" -o ./output/my-app --port 4000

# Z wasnymi zmiennymi rodowiskowymi
LITELLM_URL=http://host.docker.internal:8123 \
LITELLM_MODEL=model:1 \
docker compose run --rm reclapp-cli evolve --prompt "Create a recipe app" -o ./output/recipe-app --port 4001

# Z verbose output
docker compose run --rm reclapp-cli evolve --prompt "Create a blog app" -o ./output/blog --port 4002 --verbose
```

### 3. Wygenerowane aplikacje

Wygenerowane aplikacje s zapisywane w `./output/` na hocie (mountowany volume).

##  Przykady

### Prosta aplikacja todo

```bash
docker compose run --rm reclapp-cli evolve \
  --prompt "Create a todo app with tasks and categories" \
  -o ./output/todo-app \
  --port 4000
```

### Aplikacja z przepisami

```bash
docker compose run --rm reclapp-cli evolve \
  --prompt "Create a recipe management system with: Recipes with name, description, ingredients, instructions, prep time, cook time, difficulty level, servings, category. Categories for recipes. REST API with Express.js and TypeScript. React frontend with Tailwind CSS." \
  -o ./output/recipe-app \
  --port 4002
```

### Z wasnym modelem LM Studio

```bash
LITELLM_MODEL=your-model-name \
docker compose run --rm reclapp-cli evolve \
  --prompt "Create a blog app" \
  -o ./output/blog \
  --port 4003
```

##  Konfiguracja

### Zmienne rodowiskowe

- `LLM_PROVIDER` - Provider LLM (domylnie: `litellm`)
- `LITELLM_URL` - URL do LM Studio (domylnie: `http://host.docker.internal:8123`)
- `LITELLM_MODEL` - Nazwa modelu w LM Studio (domylnie: `model:1`)

### Volumes

- `./output` - Katalog z wygenerowanymi aplikacjami (zapisany na hocie)
- `./examples` - Przykady kontrakt贸w (read-only)
- `.` - Cay projekt (read-only, dla development)

##  Wskaz贸wki

1. **Output directory** - Wygenerowane aplikacje s w `./output/` na hocie
2. **Porty** - U偶ywaj r贸偶nych port贸w dla r贸偶nych aplikacji (4000, 4001, 4002...)
3. **LM Studio** - Upewnij si, 偶e LM Studio dziaa przed uruchomieniem
4. **Verbose mode** - Dodaj `--verbose` aby zobaczy wicej szczeg贸贸w

##  Troubleshooting

### LM Studio nie odpowiada

```bash
# Sprawd藕 czy LM Studio dziaa
curl http://localhost:8123/v1/models

# Sprawd藕 logi kontenera
docker compose logs reclapp-cli
```

### Problem z portem

```bash
# U偶yj innego portu
docker compose run --rm reclapp-cli evolve --prompt "..." -o ./output/app --port 5000
```

### Problem z uprawnieniami

```bash
# Upewnij si, 偶e katalog output istnieje i ma odpowiednie uprawnienia
mkdir -p ./output
chmod 755 ./output
```

