STUDIO_HOST=0.0.0.0
STUDIO_PORT=7860

# Ollama LLM Configuration
# Recommended models for contract generation (ranked by quality):
# 1. deepseek-coder:6.7b - Best for code generation, fast
# 2. codellama:13b - Good code understanding, slower
# 3. mistral:7b-instruct - General purpose, fast
# 4. llama2:13b - Good reasoning, slower
# 5. qwen2:7b - Good multilingual support
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=deepseek-coder:6.7b
CODE_MODEL=deepseek-coder:6.7b
