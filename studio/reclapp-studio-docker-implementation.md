# Reclapp Studio - Docker Implementation z Ollama

**Status:** ðŸŸ¢ Ready for Implementation  
**Wymagania:** Docker, 8GB+ RAM, GPU (opcjonalnie)

---

## ðŸ“‹ Quick Start

```bash
git clone https://github.com/wronai/reclapp-studio
cd reclapp-studio
docker compose up -d
open http://localhost:7860
```

---

## ðŸ—ï¸ PeÅ‚na Struktura

```
reclapp-studio/
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ studio/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ parser/
â”‚   â”‚   â”œâ”€â”€ markdown_parser.py
â”‚   â”‚   â””â”€â”€ mini_parser.py
â”‚   â”œâ”€â”€ generator/
â”‚   â”‚   â””â”€â”€ typescript.py
â”‚   â”œâ”€â”€ prompts/
â”‚   â”‚   â””â”€â”€ system.txt
â”‚   â””â”€â”€ requirements.txt
â””â”€â”€ projects/
```

---

## ðŸ“¦ docker-compose.yml

```yaml
version: '3.8'

services:
  ollama:
    image: ollama/ollama:latest
    volumes:
      - ollama_data:/root/.ollama
    ports:
      - "11434:11434"
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:11434/api/tags || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 60s

  ollama-init:
    image: ollama/ollama:latest
    depends_on:
      ollama:
        condition: service_healthy
    entrypoint: sh -c "ollama pull mistral:7b-instruct-q4_0"
    environment:
      OLLAMA_HOST: http://ollama:11434
    network_mode: "service:ollama"

  studio:
    build: ./studio
    ports:
      - "7860:7860"
    volumes:
      - ./projects:/app/projects
    environment:
      OLLAMA_HOST: http://ollama:11434
      OLLAMA_MODEL: mistral:7b-instruct-q4_0
    depends_on:
      ollama:
        condition: service_healthy

volumes:
  ollama_data:
```

---

## ðŸ” OdpowiedÅº na Pytania

### KtÃ³ry DSL jest lepszy od TypeScript?

**Rekomendacja: Dual-format (Markdown + Mini-DSL)**

| Format | Dla kogo | Kiedy uÅ¼ywaÄ‡ |
|--------|----------|--------------|
| **contract.md** | Klienci, PM, LLM | Rozmowy, dokumentacja |
| **contract.rcl** | ProgramiÅ›ci | Walidacja, edycja |
| TypeScript | Legacy | Migracja |

### PorÃ³wnanie redukcji kodu

```
TypeScript: 633 linii (baseline)
YAML:       200 linii (-68%)
Markdown:   150 linii (-76%)
Mini-DSL:    80 linii (-87%)  â† BEST
```

### KtÃ³ry model Ollama?

| Model | RAM | JakoÅ›Ä‡ | UÅ¼ycie |
|-------|-----|--------|--------|
| mistral:7b-instruct-q4_0 | 4GB | â­â­â­â­ | Rozmowa |
| codellama:7b-instruct | 4GB | â­â­â­â­â­ | Kod |
| phi3:mini | 2GB | â­â­â­ | Edge |
| llama3.2:3b | 2GB | â­â­â­ | Szybki |

---

## ðŸŽ¯ Mini-DSL Syntax (contract.rcl)

```prisma
entity Contact {
  email     email  @unique
  firstName text
  lastName  text
  company   -> Company
  tags      text[]
  score     int(0..100) = 50
}

entity Deal {
  name   text
  stage  DealStage = Lead
  amount money(PLN)
}

enum DealStage { Lead, Qualified, Won, Lost }

alert "Deal Stalled" {
  when: deal.daysInStage > 14
  notify: [email, slack]
}
```

---

## ðŸ“Š Pipeline

```
Rozmowa â†’ contract.md â†’ contract.rcl â†’ IR (JSON) â†’ target/
   â”‚           â”‚              â”‚            â”‚           â”‚
   â”‚           â”‚              â”‚            â”‚           â”œâ”€â”€ api/
   â””â”€â”€ LLM â”€â”€â”€â”€â”´â”€â”€ Parser â”€â”€â”€â”€â”´â”€â”€ Parser â”€â”€â”´â”€â”€ Gen â”€â”€â”€â”€â”œâ”€â”€ frontend/
                                                       â””â”€â”€ docker/
```

---

## ðŸš€ NastÄ™pne Kroki

1. `git clone` repozytorium
2. `docker compose up -d`
3. OtwÃ³rz http://localhost:7860
4. Rozmawiaj z AI
5. Kliknij "Generuj kod"

---

*SzczegÃ³Å‚owa implementacja w: reclapp-dsl-evolution-proposal.md*
